# ğŸ¤– Asistente Empresarial con IA HÃ­brida

Un asistente empresarial inteligente que combina modelos de IA de OpenAI con un modelo local, diseÃ±ado para responder preguntas sobre documentaciÃ³n empresarial.

## ğŸŒŸ CaracterÃ­sticas

- **Sistema HÃ­brido de IA**:
  - GPT-3.5-turbo como modelo principal
  - GPT-3.5-turbo-16k como respaldo
  - BLOOM-560m como modelo local (cuando los anteriores no estÃ¡n disponibles)

- **Procesamiento de Documentos**:
  - Soporte para PDF y archivos de texto
  - Embeddings para bÃºsqueda semÃ¡ntica
  - ExtracciÃ³n de contexto relevante

- **Arquitectura Distribuida**:
  - Servicio principal con interfaz web
  - Servicio separado para el modelo local
  - ComunicaciÃ³n vÃ­a API REST

- **Interfaz Amigable**:
  - Chat interactivo con Gradio
  - Historial de conversaciones
  - Fuentes de informaciÃ³n
  - Indicador del modelo en uso

## ğŸ—ï¸ Arquitectura

El proyecto estÃ¡ dividido en dos servicios principales:

### 1. Servicio Principal (app)
- Interfaz web con Gradio
- Procesamiento de documentos
- IntegraciÃ³n con OpenAI
- ComunicaciÃ³n con el modelo local

### 2. Servicio del Modelo Local (model)
- API REST con FastAPI
- Modelo BLOOM-560m
- Soporte para GPU
- CachÃ© persistente

## ğŸš€ Requisitos

- Docker y Docker Compose
- NVIDIA GPU (opcional, para mejor rendimiento del modelo local)
- API key de OpenAI

## ğŸ“¦ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone <url-del-repositorio>
cd asistenteia
```

2. Crear archivo `.env`:
```bash
OPENAI_API_KEY=tu_api_key_aqui
```

3. Construir y ejecutar los servicios:
```bash
docker-compose up --build
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno
- `OPENAI_API_KEY`: API key de OpenAI
- `MODEL_SERVICE_URL`: URL del servicio del modelo local (por defecto: http://model:8000)

### Puertos
- `7860`: Interfaz web (Gradio)
- `8000`: API del modelo local

## ğŸ’» Uso

1. Acceder a la interfaz web:
   - Local: http://localhost:7860
   - Remoto: URL proporcionada por Gradio

2. Ingresar nombre de usuario (por defecto: "usuario")

3. Hacer preguntas sobre la documentaciÃ³n

4. El sistema automÃ¡ticamente:
   - SeleccionarÃ¡ el mejor modelo disponible
   - BuscarÃ¡ informaciÃ³n relevante
   - ProporcionarÃ¡ respuestas con fuentes

## ğŸ”„ Flujo de Trabajo

1. **Procesamiento de Documentos**:
   - Los documentos se cargan en el directorio `docs/`
   - Se procesan y se crean embeddings
   - Se almacenan en un Ã­ndice FAISS

2. **Procesamiento de Consultas**:
   - El usuario hace una pregunta
   - El sistema busca informaciÃ³n relevante
   - Se selecciona el modelo apropiado
   - Se genera y devuelve la respuesta

3. **Sistema de Fallback**:
   - Intenta usar GPT-3.5-turbo
   - Si falla, usa GPT-3.5-turbo-16k
   - Si ambos fallan, usa BLOOM-560m local

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py              # Interfaz web con Gradio
â”‚   â”œâ”€â”€ chatbot.py          # LÃ³gica principal del chatbot
â”‚   â””â”€â”€ data_processing.py  # Procesamiento de documentos
â”œâ”€â”€ model_service/
â”‚   â””â”€â”€ app.py             # API del modelo local
â”œâ”€â”€ docs/                  # Documentos a procesar
â”œâ”€â”€ Dockerfile.app         # Dockerfile para el servicio principal
â”œâ”€â”€ Dockerfile.model       # Dockerfile para el servicio del modelo
â”œâ”€â”€ docker-compose.yml     # ConfiguraciÃ³n de Docker Compose
â”œâ”€â”€ requirements.txt       # Dependencias del servicio principal
â””â”€â”€ model_requirements.txt # Dependencias del servicio del modelo
```

## ğŸ” Monitoreo y Logging

- Logs detallados de cada servicio
- Indicadores de estado del modelo
- Mensajes de error descriptivos
- Emojis para mejor visualizaciÃ³n

## ğŸ”’ Seguridad

- ValidaciÃ³n de API keys
- AutenticaciÃ³n de usuarios
- Manejo seguro de documentos
- ComunicaciÃ³n segura entre servicios

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- OpenAI por GPT-3.5
- Hugging Face por BLOOM-560m
- Gradio por la interfaz web
- FastAPI por el framework de API 